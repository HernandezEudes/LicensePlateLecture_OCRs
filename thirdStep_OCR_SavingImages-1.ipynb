{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. OCRs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EasyOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prueba con Easy_OCR\n",
    "import pandas as pd\n",
    "import easyocr\n",
    "import re\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_reader = easyocr.Reader(['en']) #Initialzing the ocr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listText=[]\n",
    "def easyOCRLecture(image):\n",
    "  results = text_reader.readtext(image)\n",
    "  for (bbox, text, prob) in results:\n",
    "      if text == \" \":\n",
    "        print(\"No hubo ni habra\")\n",
    "      print(text)\n",
    "      plt.imshow(image)\n",
    "      listText.append(text)\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel_sharp = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "kernel_sharp = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(19):\n",
    "  image=f\"cap{i}.jpg\"\n",
    "  image = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
    "  image =cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "  sharpened = cv2.filter2D(image, -1, kernel_sharp)\n",
    "  # _, img_binaria = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "  print(i)\n",
    "  easyOCRLecture(sharpened)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  df=pd.DataFrame(listText, columns=['EasyOCR'])\n",
    "  df.to_csv(\"texto.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "\n",
    "custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789ALG'\n",
    "\n",
    "# Configura la ruta de Tesseract (ajusta según tu instalación)\n",
    "pytesseract.pytesseract.tesseract_cmd=\"tesseract.exe\"\n",
    "\n",
    "# Usar Tesseract para extraer texto\n",
    "texto = pytesseract.image_to_string(img,config=custom_config)\n",
    "\n",
    "print(\"Texto extraído:\")\n",
    "print(texto)\n",
    "\n",
    "lecturasPytesseract=[]\n",
    "\n",
    "lecturasPytesseract.append(texto)\n",
    "\n",
    "# Escribir en un archivo CSV\n",
    "with open('output.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for item in lecturasPytesseract:\n",
    "        writer.writerow([item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "!pip install google-cloud-vision\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade google-cloud-vision\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import vision\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"tesiscienciadedatos-ecc87f479584.json\"\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.vision_v1.ImageAnnotatorClient at 0x794f50112c20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client = vision.ImageAnnotatorClient()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text(path):\n",
    "    \"\"\"Detects text in the file.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "    print(\"Texts:\")\n",
    "\n",
    "    interest_text = []\n",
    "\n",
    "    for text in texts:\n",
    "        # print(f'\\n\"{text.description}\"')\n",
    "        interest_text.append(text.description)\n",
    "        vertices = [\n",
    "            f\"({vertex.x},{vertex.y})\" for vertex in text.bounding_poly.vertices\n",
    "        ]\n",
    "\n",
    "        # print(\"bounds: {}\".format(\",\".join(vertices)))\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "    return interest_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listText.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "listText=[]\n",
    "def saveImageText(text):\n",
    "\n",
    "  listText.append(text)\n",
    "  return listText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(19):\n",
    "  imagen=(f\"/content/imgs/cap{i}.jpg\")\n",
    "  print(imagen)\n",
    "  ver=detect_text(imagen)\n",
    "  img=cv2.imread(imagen, )\n",
    "  img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "  # plt.imshow(img)\n",
    "  if len(ver)>0:\n",
    "    print(ver[0])\n",
    "    saveImageText(ver[0])\n",
    "  else:\n",
    "    saveImageText(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(listText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  df=pd.DataFrame(listText, columns=['GoogleVision'])\n",
    "  df.to_csv(\"texto.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
